{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jS-emuiPhx85",
        "outputId": "c8bf8a94-39f7-4b67-81c6-5ea0808e1e6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting full model training process (Grid Search + Final Fit)...\n",
            "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
            "Grid search completed.\n",
            "Best parameters: {'C': 10, 'epsilon': 0.1, 'gamma': 'scale'}\n",
            "Best CV RMSE: 0.56°C\n",
            "Full training process completed in 339.92 seconds\n",
            "\n",
            "Model Evaluation Metrics:\n",
            "MSE: 0.2469\n",
            "RMSE: 0.4969°C\n",
            "MAE: 0.3695°C\n",
            "R² Score: 0.9712\n",
            "\n",
            "Feature correlation with prediction error:\n",
            "city_name_Nuwara Eliya    0.128184\n",
            "elevation                 0.123257\n",
            "rain_sum (mm)             0.082309\n",
            "precipitation_sum (mm)    0.082309\n",
            "longitude                 0.043921\n",
            "city_name_Kurunegala      0.022113\n",
            "city_name_Bandarawela     0.021697\n",
            "city_name_Kegalle         0.019041\n",
            "city_name_Badulla         0.015817\n",
            "city_name_Kandy           0.012638\n",
            "Name: abs_error, dtype: float64\n",
            "\n",
            "Example Prediction:\n",
            "Predicted temperature: 32.35°C\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load datasets\n",
        "weather = pd.read_csv('weatherData.csv')\n",
        "location = pd.read_csv('locationData.csv')\n",
        "\n",
        "# Strip whitespace from column names\n",
        "weather.columns = weather.columns.str.strip()\n",
        "location.columns = location.columns.str.strip()\n",
        "\n",
        "# Merge and clean data\n",
        "data = pd.merge(weather, location, on='location_id')\n",
        "data.columns = data.columns.str.strip()\n",
        "\n",
        "# Define target variable\n",
        "target = 'temperature_2m_mean (°C)'\n",
        "\n",
        "drop_cols = [\n",
        "    'sunrise', 'sunset', 'utc_offset_seconds', 'timezone', 'timezone_abbreviation',\n",
        "    'weather_code (wmo code)', 'temperature_2m_max (°C)', 'temperature_2m_min (°C)',\n",
        "    'apparent_temperature_max (°C)', 'apparent_temperature_min (°C)', 'apparent_temperature_mean (°C)'\n",
        "]\n",
        "drop_cols_present = [c for c in drop_cols if c in data.columns]\n",
        "data.drop(columns=drop_cols_present, inplace=True)\n",
        "\n",
        "# Fill missing values\n",
        "data.fillna(data.mean(numeric_only=True), inplace=True)\n",
        "\n",
        "# Encode city names\n",
        "if 'city_name' in data.columns:\n",
        "    data = pd.get_dummies(data, columns=['city_name'], drop_first=True)\n",
        "\n",
        "# Extract date components\n",
        "if 'date' in data.columns:\n",
        "    data['date'] = pd.to_datetime(data['date'], errors='coerce')\n",
        "    data['month'] = data['date'].dt.month\n",
        "    data['day'] = data['date'].dt.day\n",
        "    data['day_of_year'] = data['date'].dt.dayofyear\n",
        "    data.drop(columns=['date'], inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "X = data.drop(columns=[target, 'location_id'])\n",
        "y = data[target]\n",
        "\n",
        "# Sample data\n",
        "sample_size = min(15000, len(X))\n",
        "indices = np.random.choice(len(X), sample_size, replace=False)\n",
        "X_sample = X.iloc[indices]\n",
        "y_sample = y.iloc[indices]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Show correlations\n",
        "correlations = X_train.corrwith(y_train).sort_values(ascending=False)\n",
        "\n",
        "# SVR parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'epsilon': [0.01, 0.1, 0.2],\n",
        "    'gamma': ['scale', 'auto', 0.1]\n",
        "}\n",
        "\n",
        "# Grid search sample size\n",
        "grid_sample_size = min(5000, len(X_train))\n",
        "if len(X_train) > grid_sample_size:\n",
        "    grid_indices = np.random.choice(len(X_train), grid_sample_size, replace=False)\n",
        "    X_grid_train = X_train_scaled[grid_indices]\n",
        "    y_grid_train = y_train.iloc[grid_indices].values\n",
        "else:\n",
        "    X_grid_train = X_train_scaled\n",
        "    y_grid_train = y_train.values\n",
        "\n",
        "# Grid search and final training combined timing\n",
        "print(\"\\nStarting full model training process (Grid Search + Final Fit)...\")\n",
        "full_train_start = time.time()\n",
        "\n",
        "# Grid search\n",
        "svr = SVR(kernel='rbf')\n",
        "grid = GridSearchCV(\n",
        "    svr, param_grid, cv=3,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1, verbose=1\n",
        ")\n",
        "grid.fit(X_grid_train, y_grid_train)\n",
        "print(\"Grid search completed.\")\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(f\"Best CV RMSE: {(-grid.best_score_)**0.5:.2f}°C\")\n",
        "\n",
        "# Final model training\n",
        "best_params = grid.best_params_\n",
        "final_model = SVR(kernel='rbf', **best_params)\n",
        "final_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "full_train_end = time.time()\n",
        "print(f\"Full training process completed in {full_train_end - full_train_start:.2f} seconds\")\n",
        "\n",
        "# Predict\n",
        "y_pred = final_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nModel Evaluation Metrics:\")\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}°C\")\n",
        "print(f\"MAE: {mae:.4f}°C\")\n",
        "print(f\"R² Score: {r2:.4f}\")\n",
        "\n",
        "# Save plots\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "plt.xlabel('Actual Temperature (°C)')\n",
        "plt.ylabel('Predicted Temperature (°C)')\n",
        "plt.title('Actual vs Predicted Mean Temperature')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig('temperature_prediction_results.png')\n",
        "plt.close()\n",
        "\n",
        "errors = y_pred - y_test\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(errors, bins=30, alpha=0.75)\n",
        "plt.xlabel('Prediction Error (°C)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Prediction Error Distribution')\n",
        "plt.grid(True)\n",
        "plt.axvline(x=0, color='r', linestyle='--')\n",
        "plt.tight_layout()\n",
        "plt.savefig('error_distribution.png')\n",
        "plt.close()\n",
        "\n",
        "# Feature error correlation\n",
        "error_abs = np.abs(errors)\n",
        "error_series = pd.Series(error_abs, index=y_test.index)\n",
        "feature_df = X_test.copy()\n",
        "feature_df['abs_error'] = error_series\n",
        "error_correlations = feature_df.corr()['abs_error'].drop('abs_error').sort_values(ascending=False)\n",
        "print(\"\\nFeature correlation with prediction error:\")\n",
        "print(error_correlations.head(10))\n",
        "\n",
        "# Feature importance plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "top_corrs = correlations.abs().sort_values(ascending=False).head(10)\n",
        "top_corrs_withsign = correlations[top_corrs.index]\n",
        "bars = plt.bar(top_corrs_withsign.index, top_corrs_withsign.values)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.ylabel('Correlation with Temperature')\n",
        "plt.title('Top 10 Features by Correlation with Target')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.savefig('feature_importance.png')\n",
        "plt.close()\n",
        "\n",
        "# Prediction function\n",
        "def predict_temperature(features_df, model=final_model, scaler=scaler):\n",
        "    required_features = X_train.columns\n",
        "    missing_features = set(required_features) - set(features_df.columns)\n",
        "    if missing_features:\n",
        "        print(f\"Warning: Missing features: {missing_features}\")\n",
        "        for feature in missing_features:\n",
        "            features_df[feature] = 0\n",
        "    features_df = features_df[required_features]\n",
        "    features_scaled = scaler.transform(features_df)\n",
        "    return model.predict(features_scaled)\n",
        "\n",
        "# Example prediction\n",
        "example_data = pd.DataFrame({\n",
        "    'daylight_duration (s)': [43200],\n",
        "    'sunshine_duration (s)': [25000],\n",
        "    'precipitation_sum (mm)': [0.5],\n",
        "    'rain_sum (mm)': [0.5],\n",
        "    'precipitation_hours (h)': [2],\n",
        "    'wind_speed_10m_max (km/h)': [12.4],\n",
        "    'wind_gusts_10m_max (km/h)': [18.6],\n",
        "    'wind_direction_10m_dominant (°)': [180],\n",
        "    'shortwave_radiation_sum (MJ/m²)': [15.3],\n",
        "    'et0_fao_evapotranspiration (mm)': [4.2],\n",
        "    'latitude': [6.9271],\n",
        "    'longitude': [79.8612],\n",
        "    'elevation': [7],\n",
        "    'month': [4],\n",
        "    'day': [15],\n",
        "    'day_of_year': [105]\n",
        "})\n",
        "for col in X_train.columns:\n",
        "    if 'city_name_' in col and col not in example_data.columns:\n",
        "        example_data[col] = 0\n",
        "\n",
        "# Predict and print\n",
        "predicted_temp = predict_temperature(example_data)\n",
        "print(f\"\\nExample Prediction:\\nPredicted temperature: {predicted_temp[0]:.2f}°C\")\n"
      ]
    }
  ]
}